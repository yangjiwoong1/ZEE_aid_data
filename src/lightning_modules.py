import os
import datetime
import torch
import pytorch_lightning as pl
import wandb
from argparse import ArgumentParser
from kornia.contrib import extract_tensor_patches
from torch.optim import Adam, SGD
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from torchvision.utils import make_grid
from src.losses import mse_loss, mae_loss, ssim_loss, tv_loss
from src.modules import BicubicUpscaledBaseline
import pandas as pd

class LitModel(pl.LightningModule):
    """
    Lightning Module wrapper.
    Implements the forward, loss, train/val/test step functions and logging.
    Parses and adds default model arguments.
    """

    def __init__(self, backbone, **kws) -> None:
        """
        Initialises the LightningModule with the backbone and the default arguments.
        The hyperparameters are fetchd from the hparams attribute.

        Args:
            backbone (nn.Module): Backbone model, as generated by train.py.
        """
        super().__init__()
        self.save_hyperparameters()  # save arguments(backbone, **kws) in self.hparams
        self.backbone = backbone # maybe SRCNN
        self.transform = self.hparams.transform  # transform as a torch module

        self.baseline = BicubicUpscaledBaseline(
            output_size=self.backbone.output_size,
            interpolation="bicubic",
        )

        self.check_loss_functions_weights_are_valid() # check if the loss functions weights sum to 1
        self.create_metrics() # init metrics variables for train, val, test
        self.enable_benchmark_logging() # init benchmark logging variables

    def check_loss_functions_weights_are_valid(self):
        """
        loss 가중치 합이 1이 되는 지 검사하는 함수
        """
        assert self.hparams.w_mse + self.hparams.w_mae + self.hparams.w_ssim + self.hparams.w_tv == 1

    def create_metrics(self):
        """Creates metrics (MSE, MAE, SSIM, TV) for the train, validation and test sets."""

        # TODO: dict of train/val/test metrics
        self.train_metrics = self.metrics_factory("train")
        self.val_metrics = self.metrics_factory("val")
        self.test_metrics = self.metrics_factory("test")
        self.baseline_train_metrics = self.metrics_factory("train")
        self.baseline_val_metrics = self.metrics_factory("val")
        self.baseline_test_metrics = self.metrics_factory("test")

    def enable_benchmark_logging(self):
        if self.hparams.benchmark_logging:
            self.logging = {}
            self.logging['current_idx'] = 1
            self.logging['log'] = pd.DataFrame()
            self.log_path = '../log' # TODO: save log

    def metrics_factory(self, prefix):
        """
        Creates a dictionary of metrics (MSE, MAE, SSIM, TV) for the train, validation and test sets.

        Args:
            prefix (str): Prefix for the metrics (train/val/test).

        Returns:
            dict: Dictionary of metrics.
        """
        return {
            f"{prefix}/MSE": lambda y_hat, y: mse_loss(y_hat, y),
            f"{prefix}/MAE": lambda y_hat, y: mae_loss(y_hat, y),
            f"{prefix}/SSIM_loss": lambda y_hat, y: ssim_loss(y_hat, y, window_size=5),
            f"{prefix}/TV": lambda y_hat, y=None: tv_loss(y_hat),
        }

    def forward(self, x):
        """Forward pass of the model.

        Args:
            x (Tensor): Input tensor (LR) of dimensions (batch_size, channels, height, width).

        Returns:
            Tensor: Output tensor (y_hat) of dimensions (batch_size, channels, height, width).
        """
        return self.backbone(x)

    def validation_log(self, y, m, baseline_m, prefix):

        log = pd.DataFrame(
            columns=[
                "MSE",
                "MAE",
                "SSIM_loss",
                "TV",
                "PSNR",
                "Baseline MSE",
                "Baseline PSNR",
            ]
        )
        mse, mae, ssim_loss, tv, psnr = (
            m[f"{prefix}/MSE"],
            m[f"{prefix}/MAE"],
            m[f"{prefix}/SSIM_loss"],
            m[f"{prefix}/TV"],
            m[f"{prefix}/PSNR"],
        )
        baseline_mse, baseline_psnr = (
            baseline_m[f"{prefix}/MSE"],
            baseline_m[f"{prefix}/PSNR_baseline"],
        )
        
        baseline_m = list(baseline_m.values())
        for batch_item in range(y.shape[0]):  # batch_size
            log.loc[self.logging["current_idx"]] = (
                mse[batch_item].detach().item(),
                mae[batch_item].detach().item(),
                ssim_loss[batch_item].detach().item(),
                tv[batch_item].detach().item(),
                psnr[batch_item].detach().item(),
                baseline_mse[batch_item].detach().item(),
                baseline_psnr[batch_item].detach().item(),
            )
            self.logging["current_idx"] += 1
        self.logging["log"] = pd.concat([self.logging["log"], log])

    def loss(self, batch, metrics, baseline_metrics, prefix) -> dict[str, torch.Tensor]:
        """Computes the loss for a batch using the provided metrics.

        Args:
            batch (dict): Dictionary with the batches for LR/HR
            metrics (dict of Callable): Dictionary with the metrics to use.
            baseline_metrics (dict of Callable): Dictionary with the metrics to use for the baseline.
            prefix (str): Prefix for the metrics (train/val/test).

        Returns:
            dict: Dictionary with the losses.
        """
        batch = self.transform(batch)  # GPU/Batched data augmentation
        x, y = batch["lr"], batch["hr"] # (B, C, H, W)

        # call forward() - backbone
        y_hat = self(x) # (B, C, H, W)
        m, mse, mae, ssim, tv = self.compute_metrics(y, y_hat, metrics, prefix)

        # call baseline.forward() - baseline
        y_hat_base = self.baseline(x)
        baseline_m = self.compute_baseline_metrics(y, y_hat_base, m, baseline_metrics, prefix)

        # loss 계산
        loss = (
            (self.hparams.w_mse * mse)
            + (self.hparams.w_mae * mae)
            + (self.hparams.w_tv * tv)
            + (self.hparams.w_ssim * ssim)
        )

        if self.hparams.benchmark_logging:
            self.validation_log(y, self.detach_dict(m), self.detach_dict(baseline_m), prefix)

        return {
            "y_hat": y_hat,
            "y_hat_base": y_hat_base,
            "y": y,
            "metrics": m, # reduce 전 metrics
            "baseline_metrics": baseline_m, # reduce 전 baseline metrics
            "loss": loss, # reduce 전 backbone loss
        }

    def compute_metrics(self, y, y_hat, metrics, prefix):
        """Computes the metrics for a batch (MSE, MAE, SSIM, TV, PSNR).

        Args:
            y (torch.Tensor): Target tensor (HR) of dimensions (batch_size, channels, height, width).
            y_hat (torch.Tensor): Output tensor (SR) of dimensions (batch_size, channels, height, width).
            metrics (dict of Callable): Dictionary with the metric functions to use.
            prefix (str): Prefix for the metrics (train/val/test).

        Returns:
            dict: Dictionary with the metrics (MSE, MAE, SSIM, TV, PSNR).
            The metrics themselves, the MSE, MAE, SSIM, TV.
        """
        metric_fns = metrics  # 원본 보존

        # compute metrics
        values = {name: fn(y_hat, y) for name, fn in metric_fns.items()}

        mse = values[f"{prefix}/MSE"].clone()
        mae = values[f"{prefix}/MAE"].clone()
        ssim = values[f"{prefix}/SSIM_loss"].clone()
        tv = values[f"{prefix}/TV"].clone()
        values[f"{prefix}/PSNR"] = -10.0 * torch.log10(mse)
        # Also provide SSIM metric (1 - SSIM_loss)
        values[f"{prefix}/SSIM"] = 1.0 - values[f"{prefix}/SSIM_loss"]
        return values, mse, mae, ssim, tv

    def compute_baseline_metrics(
        self, y, y_hat_base, metrics, baseline_metrics, prefix
    ):
        """Computes the baseline metrics for a batch (MSE, MAE, SSIM, TV, PSNR_baseline, PSNR_ratio).

        Args:
            y (torch.Tensor): Target tensor (HR) of dimensions (batch_size, channels, height, width).
            y_hat_base (torch.Tensor): Baseline tensor (single upscaled LR) of dimensions (batch_size, channels, height, width).
            metrics (dict of Callable): Dictionary with the metric functions to use.
            baseline_metrics (dict of Callable): Dictionary with the baseline metric functions to use.
            prefix (str): Prefix for the metrics (train/val/test).

        Returns:
            dict: Dictionary with the baseline metrics (MSE, MAE, SSIM, TV, PSNR_baseline, PSNR_ratio).
        """
        baseline_metric_fns = baseline_metrics  # 원본 보존
        # compute baseline metrics
        values = {name: fn(y_hat_base, y) for name, fn in baseline_metric_fns.items()}

        # compute PSNR_baseline
        baseline_psnr = -10.0 * torch.log10(mse_loss(y_hat_base, y))
        values[f"{prefix}/PSNR_baseline"] = baseline_psnr
        # Baseline SSIM (1 - SSIM_loss)
        values[f"{prefix}/SSIM"] = 1.0 - values[f"{prefix}/SSIM_loss"]

        values[f"{prefix}/PSNR_ratio"] = (
            values[f"{prefix}/PSNR_baseline"] / (metrics[f"{prefix}/PSNR"]+ 1e-6) # 0으로 나누는 것을 방지
        )

        return values

    def training_step(self, batch, batch_idx):
        """
        Calls the forward pass, computes the loss and metrics for the training batch.
        Logs the reduced metrics.

        Args:
            batch (dict): Dictionary with the batches for LR/HR

        Returns:
            dict: Dictionary with the training loss and metrics.
        """
        loss_output = self.loss(
            batch, self.train_metrics, self.baseline_train_metrics, prefix="train"
        )

        metrics, metrics_reduced, loss_reduced = self.unpack_and_reduce_metrics(
            loss_output, prefix="train"
        )

        self.log_dict(metrics_reduced, on_step=True, on_epoch=True)
        self.log("train/loss", loss_reduced, on_step=True, on_epoch=True, prog_bar=True)
        return {"loss": loss_reduced, "metrics": metrics}

    def validation_step(self, batch, batch_idx):
        """
        Calls the forward pass, computes the loss and metrics for the validation batch.
        Logs the reduced metrics.

        Args:
            batch (dict): Dictionary with the batches for LR/HR

        Returns:
            dict: Dictionary with the validation loss and metrics.
        """
        loss_output = self.loss(
            batch, self.val_metrics, self.baseline_val_metrics, prefix="val"
        )
        _, metrics_reduced, loss_reduced = self.unpack_and_reduce_metrics(loss_output, prefix="val")
        self.log_dict(metrics_reduced, on_step=False, on_epoch=True)
        self.log("val/loss", loss_reduced, on_step=False, on_epoch=True, prog_bar=True)
        return loss_output["loss"]  # Instance-wise loss

    def validation_epoch_end(self, validation_step_output):
        instance_loss = torch.cat(validation_step_output).to("cpu")
        
        # WandB 로거가 있을 때만 히스토그램 로깅
        if isinstance(self.logger, pl.loggers.WandbLogger):
            try:
                self.logger.experiment.log(
                    {
                        "val/loss_hist": wandb.Histogram(instance_loss),
                        "global_step": self.global_step,
                    }
                )
            except ValueError as e:
                print(e)

    def test_step(self, batch, batch_idx):
        """
        Calls the forward pass, computes the loss and metrics for the test batch.
        Logs the reduced metrics.

        Args:
            batch (dict): Dictionary with the batches for LR/HR

        Returns:
            torch.Tensor: Test loss.
        """
        loss_output = self.loss(
            batch, self.test_metrics, self.baseline_test_metrics, prefix="test"
        )

        _, metrics_reduced, loss_reduced = self.unpack_and_reduce_metrics(loss_output, prefix="test")

        self.log_dict(metrics_reduced, on_step=False, on_epoch=True)
        self.log("test/loss", loss_reduced, on_step=False, on_epoch=True)
        return loss_output["loss"]  # Instance-wise loss

    def unpack_and_reduce_metrics(self, loss_output, prefix):
        """Unpacks the metrics for a split (prefix) and reduces them (mean).

        Args:
            loss_output (dict): Dictionary with the loss and metrics.
        prefix : str
            Prefix for the metrics (train/val/test).

        Returns:
            dict: Dictionary with the reduced (mean) metrics.
        """
        metrics = loss_output["metrics"]
        metrics_reduced = {
            metric_name: metric.mean() for metric_name, metric in metrics.items()
        }
        loss_reduced = loss_output["loss"].mean()
        return metrics, metrics_reduced, loss_reduced

    def configure_optimizers(self):
        """Configures the optimizers for the model based on the hyperparameters.
        Uses the learning rate and weight decay parameters for the Adam optimizer.
        Uses the learning rate, weight decay and momentum parameters for the SGD optimizer.

        Uses the cos_anneal_T_0 hyperparameter for the cosine annealing scheduler.
        See: https://arxiv.org/abs/1608.03983

        Returns:
            dict: Dictionary containing the optimizer, scheduler and monitor key (val/loss).
        """
        if self.hparams.optimizer == "adam":
            optimizer = Adam(
                self.parameters(),
                lr=self.hparams.learning_rate,
                weight_decay=self.hparams.weight_decay,
            )

        elif self.hparams.optimizer == "sgd":
            optimizer = SGD(
                self.parameters(),
                lr=self.hparams.learning_rate,
                weight_decay=self.hparams.weight_decay,
                momentum=self.hparams.momentum,
            )
        scheduler = CosineAnnealingWarmRestarts(
            optimizer, T_0=self.hparams.cos_anneal_T_0
        )

        return {
            "optimizer": optimizer,
            "lr_scheduler": scheduler,
            "monitor": "val/loss",
        }

    @staticmethod
    def detach_dict(dict):
        """
        Detaches the tensors in a dictionary(텐서를 연산그래프에서 분리)
        
        Args:
            dict (dict of Tensor): Dictionary containing the tensors to detach.

        Returns:
            dict of Tensor: Dictionary containing the detached tensors.
        """
        for tensor_key in dict:
            if dict[tensor_key].requires_grad:
                dict[tensor_key] = dict[tensor_key].detach()
        return dict
    
    @staticmethod
    def add_model_specific_args(parent_parser):
        """Add model-specific arguments (and their default values) to the parser.

        Args:
            parent_parser (argparse.ArgumentParser): argparse.ArgumentParser to add to.

        Returns:
            argparse.ArgumentParser: ArgumentParser with the model-specific arguments added.
        """
        parser = ArgumentParser(parents=[parent_parser], add_help=False)
        # Model arguments
        parser.add_argument("--model", default="SRCNN", type=str)
        parser.add_argument("--hidden_channels", default=64, type=int)
        parser.add_argument("--residual_layers", default=4, type=int)
        parser.add_argument("--zoom_factor", default=4, type=int)
        parser.add_argument("--padding_mode", default="reflect", type=str)
        parser.add_argument("--kernel_size", default=3, type=int)
        parser.add_argument("--sr_kernel_size", default=1, type=int)
        parser.add_argument("--use_dropout", default=False, type=bool)
        parser.add_argument("--use_batchnorm", default=False, type=bool)

        # Optimizer arguments
        parser.add_argument("--optimizer", default="adam", type=str)
        parser.add_argument("--learning_rate", default=5e-4, type=float)
        parser.add_argument("--learning_rate_decay", default=0.97, type=float)
        parser.add_argument("--learning_rate_patience", default=3, type=int)
        parser.add_argument("--momentum", type=float, default=0.9)
        parser.add_argument("--weight_decay", type=float, default=1e-4)
        parser.add_argument("--cos_anneal_T_0", type=int, default=300)

        # Data arguments
        parser.add_argument("--output_size", nargs=2, type=int, default=(600, 600))
        parser.add_argument("--chip_size", nargs=2, type=int, default=(600, 600))
        parser.add_argument("--chip_stride", nargs=2, type=int, default=(600, 600))
 
        # Loss weights: MSE, MAE, SSIM, TV
        parser.add_argument("--w_mse", default=1.0, type=float)
        parser.add_argument("--w_mae", default=0.0, type=float)
        parser.add_argument("--w_ssim", default=0.0, type=float)
        parser.add_argument("--w_tv", default=0.0, type=float)

        return parser


class ImagePredictionLogger(pl.Callback):
    """Logs the model losses, inputs and outputs to WandB.

    Parameters
    ----------
    pl : pl.LightningModule
        Lightning module containing the model.
    """

    def __init__(
        self,
        train_dataloader,
        val_dataloader,
        test_dataloader,
        log_every_n_epochs=1,
        window_size=None,
    ):
        """
        Initialize the logger.

        Args:
            train_dataloader (torch.utils.data.DataLoader): Training dataloader.
            val_dataloader (torch.utils.data.DataLoader): Validation dataloader.
            test_dataloader (torch.utils.data.DataLoader): Test dataloader.
            log_every_n_epochs (int, optional): Log every n epochs.
            window_size (tuple of int, optional): Size of the window to use for the patches.
        """
        super().__init__()
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.test_dataloader = test_dataloader
        self.log_every_n_epochs = log_every_n_epochs
        self.window_size = window_size
        self.baseline_psnr = None

    def _on_epoch_end(self, prefix, batch, trainer, pl_module):
        """
        Log the current epoch's metrics and images.

        Args:
            prefix (str): The split prefix (train, val, test).
            batch (dict): Dictionary with the batches for LR/HR
            trainer (pytorch_lightning.trainer.Trainer): The trainer.
            pl_module (pytorch_lightning.LightningModule): The model.
        """
        lr, hr = batch["lr"], batch["hr"]
        batch = self.move_batch_to_device(batch, pl_module.device)

        metrics, baseline_metrics = self.fetch_metrics_for_split(prefix, pl_module)

        loss_output, instance_psnr, baseline_psnr, instance_ssim, baseline_ssim = self.get_losses_from_metrics(
            batch, metrics, baseline_metrics, pl_module, prefix
        )
        sr, sr_base = self.get_output_and_baseline(loss_output)

        window_size, window_size_hr = self.calculate_window_size(lr, hr, pl_module)

        lr, hr, sr, sr_base = self.extract_patches_from_images(
            sr, sr_base, lr, hr, window_size, window_size_hr
        )

        instance_psnr, baseline_psnr = self.extract_psnr_values_for_patches(
            sr, sr_base, lr, instance_psnr, baseline_psnr
        )
        # Expand SSIM values per patch as well to align with images
        instance_ssim = self.expand_values_for_patches(instance_ssim, sr, lr)
        baseline_ssim = self.expand_values_for_patches(baseline_ssim, sr_base, lr)

        self.log_image_previews_to_wandb(
            sr,
            sr_base,
            lr,
            hr,
            instance_psnr,
            baseline_psnr,
            instance_ssim,
            baseline_ssim,
            prefix,
            trainer,
        )

    def move_batch_to_device(self, batch, device):
        """Move all tensors from batch to the specified device.

        Parameters
        ----------
        batch : dict
            A batch of data.
        device : torch.device
            The device to move the tensors to.

        Returns
        -------
        dict
            The batch with all tensors moved to the specified device.
        """
        return {key: value.to(device) for key, value in batch.items()}

    def fetch_metrics_for_split(self, prefix, pl_module):
        """Fetch the metrics for the split.

        Parameters
        ----------
        prefix : str
            The prefix for the metrics.
        pl_module : pytorch_lightning.LightningModule
            The model.

        Returns
        -------
        dict, dict
            The metrics and baseline metrics for the current batch.
        """
        if prefix == "val":
            metrics = pl_module.val_metrics
            baseline_metrics = pl_module.baseline_val_metrics
        elif prefix == "train":
            metrics = pl_module.train_metrics
            baseline_metrics = pl_module.baseline_train_metrics
        elif prefix == "test":
            metrics = pl_module.test_metrics
            baseline_metrics = pl_module.baseline_test_metrics
        return metrics, baseline_metrics

    def get_losses_from_metrics(
        self, batch, metrics, baseline_metrics, pl_module, prefix
    ):
        """Get the losses that will be logged from the metrics.

        Parameters
        ----------

        batch : dict
            The batch.
        metrics : dict
            The metrics for the current batch.
        baseline_metrics : dict
            The baseline metrics for the current batch.
        pl_module : pytorch_lightning.LightningModule
            The model.
        prefix : str
            The prefix for the metrics.

        Returns
        -------
        dict, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor
            The loss output, the PSNR and SSIM values for the SR and Baseline images in the batch.
        """
        loss_output = pl_module.loss(batch, metrics, baseline_metrics, prefix=prefix)
        instance_psnr = loss_output["metrics"][f"{prefix}/PSNR"].to("cpu")
        baseline_psnr = loss_output["baseline_metrics"][f"{prefix}/PSNR_baseline"].to(
            "cpu"
        )
        instance_ssim = loss_output["metrics"][f"{prefix}/SSIM"].to("cpu")
        baseline_ssim = loss_output["baseline_metrics"][f"{prefix}/SSIM"].to("cpu")

        return loss_output, instance_psnr, baseline_psnr, instance_ssim, baseline_ssim

    def get_output_and_baseline(self, loss_output):
        """Get the output and baseline images from the loss output.

        Parameters
        ----------
        loss_output : dict
            The loss output.

        Returns
        -------
        torch.Tensor, torch.Tensor
            The output and baseline images.
        """
        sr = loss_output["y_hat"].to("cpu")
        sr_base = loss_output["y_hat_base"].to("cpu")
        return sr, sr_base

    def calculate_window_size(self, lr, hr, pl_module):
        """Calculate the window size for the patches.

        Parameters
        ----------
        lr : torch.Tensor
            The LR image.
        hr : torch.Tensor
            The HR image.
        pl_module : pytorch_lightning.LightningModule
            The model.

        Returns
        -------
        tuple of int, tuple of int
            The window size for lr and hr.
        """
        lr_height, lr_width = lr.shape[-2:]
        hr_height, hr_width = hr.shape[-2:]
        ratio_hr_lr_height, ratio_hr_lr_width = (
            hr_height / lr_height,
            hr_width / lr_width,
        )
        window_size = self.window_size or pl_module.hparams.input_size
        assert (
            window_size[0] <= pl_module.hparams.chip_size[0]
            and window_size[1] <= pl_module.hparams.chip_size[1]
        )
        window_size_hr = (
            round(ratio_hr_lr_height * window_size[0]),
            round(ratio_hr_lr_width * window_size[1]),
        )

        return window_size, window_size_hr

    def extract_patches_from_images(
        self, sr, sr_base, lr, hr, window_size, window_size_hr
    ):
        """Extract the patches from the images.

        Parameters
        ----------
        sr : torch.Tensor
            The SR image.
        sr_base : torch.Tensor
            The baseline SR image.
        hr : torch.Tensor
            The HR image.
        window_size : tuple of int
            The window size.
        window_size_hr : tuple of int
            The window size for the HR image.

        Returns
        -------
        torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor
            The extracted SR, SR_base, LR, HR images.
        """
        lr = self.batch_patch_extractor(
            lr, window_size
        )  # (batch*patches, channels, patch_height, patch_width)
        hr = self.batch_patch_extractor(hr, window_size_hr)
        sr = self.batch_patch_extractor(sr, window_size_hr)
        sr_base = self.batch_patch_extractor(sr_base, window_size_hr)
        return lr, hr, sr, sr_base

    @staticmethod
    def batch_patch_extractor(x, window_size):
        """Extract patches from a batch of images.

        Parameters
        ----------
        x : Tensor
            A batch of images (batch, channels, height, width).
        window_size : tuple of int
            The size of the patch to extract.

        Returns
        -------
        Tensor
            A batch of patches extracted from the images (batch*patches, channels, patch_height, patch_width), with patches extracted patches.
        """
        batch, channels, height, width = x.shape
        x = extract_tensor_patches(
            x,
            window_size,
            stride=window_size,
        )
        _, patches, _, patch_height, patch_width = x.shape
        return x.view(batch * patches, channels, patch_height, patch_width)

    def extract_psnr_values_for_patches(
        self, sr, sr_base, lr, instance_psnr, baseline_psnr
    ):
        """Extract the PSNR values for the patches.

        Parameters
        ----------
        sr : torch.Tensor
            The SR image.
        sr_base : torch.Tensor
            The baseline SR image.
        lr : torch.Tensor
            The LR image.
        instance_psnr : torch.Tensor
            The instance PSNR values.
        baseline_psnr : torch.Tensor
            The baseline PSNR values.

        Returns
        -------
        torch.Tensor, torch.Tensor
            The extracted instance and baseline PSNR values.
        """
        instance_psnr = (
            instance_psnr[None].expand(sr.shape[0] // lr.shape[0], -1).flatten()
        )
        baseline_psnr = (
            baseline_psnr[None].expand(sr_base.shape[0] // lr.shape[0], -1).flatten()
        )

        return instance_psnr, baseline_psnr

    @staticmethod
    def expand_values_for_patches(values, target_images, lr_images):
        """Broadcast per-image metric values to per-patch arrays.

        Parameters
        ----------
        values : torch.Tensor
            Per-image metric tensor of shape (batch,)
        target_images : torch.Tensor
            Tensor after patch extraction whose batch length to match (e.g., sr)
        lr_images : torch.Tensor
            LR tensor after patch extraction to compute expansion factor

        Returns
        -------
        torch.Tensor
            Per-patch broadcasted metric tensor aligned with target_images.
        """
        return values[None].expand(target_images.shape[0] // lr_images.shape[0], -1).flatten()

    def log_image_previews_to_wandb(
        self,
        sr,
        sr_base,
        lr,
        hr,
        instance_psnr,
        baseline_psnr,
        instance_ssim,
        baseline_ssim,
        prefix,
        trainer,
    ):
        """Log the current epoch's images to WandB.

        Parameters
        ----------
        sr : torch.Tensor
            The SR image.
        sr_base : torch.Tensor
            The baseline SR image.
        lr : torch.Tensor
            The LR image.
        hr : torch.Tensor
            The HR image.
        instance_psnr : torch.Tensor
            The instance PSNR values.
        baseline_psnr : torch.Tensor
            The baseline PSNR values.
        pl_module : pl.LightningModule
            The model.
        prefix : str
            The split prefix (train, val, test).
        trainer : pytorch_lightning.trainer.Trainer
            The trainer.
        """
        trainer.logger.experiment.log(
            {
                f"{prefix}-lr": [
                    wandb.Image(
                        make_grid(lr_image, nrow=1, normalize=True, scale_each=True),
                        caption=f"lr",
                    )
                    for lr_image in lr
                ],
                f"{prefix}-hr": [
                    wandb.Image(
                        make_grid(hr_image, nrow=1, normalize=True, scale_each=True),
                        caption=f"hr",
                    )
                    for hr_image in hr
                ],
                f"{prefix}-baseline_upscaled_bicubic": [
                    wandb.Image(
                        make_grid(baseline_image, nrow=1, normalize=True, scale_each=True),
                        caption=f"baseline:PSNR {baseline_psnr.item():.2f}, SSIM {baseline_ssim.item():.3f}",
                    )
                    for baseline_image, baseline_psnr, baseline_ssim in zip(sr_base, baseline_psnr, baseline_ssim)
                ],
                f"{prefix}-sr": [
                    wandb.Image(
                        make_grid(image, nrow=1, normalize=True, scale_each=True),
                        caption=f"sr:PSNR {sr_psnr.item():.2f}, SSIM {sr_ssim.item():.3f}",
                    )
                    for image, sr_psnr, sr_ssim in zip(sr, instance_psnr, instance_ssim)
                ],
            }
        )

    def on_validation_epoch_end(self, trainer, pl_module):
        """Called at the end of the validation epoch.
        If the current epoch should be logged (i.e. the current epoch is a multiple of the log interval),
        then _on_epoch_end is called for the next batch of the validation set.

        Parameters
        ----------
        trainer : pytorch_lightning.trainer.Trainer
            The trainer.
        pl_module : pytorch_lightning.LightningModule
            The model.
        """
        if trainer.current_epoch % self.log_every_n_epochs == 0:
            batch = next(iter(self.val_dataloader))
            self._on_epoch_end("val", batch, trainer, pl_module)

    def on_test_epoch_end(self, trainer, pl_module):
        """Called at the end of the test epoch.

        Parameters
        ----------
        trainer : pytorch_lightning.trainer.Trainer
            The trainer.
        pl_module : pytorch_lightning.LightningModule
            The model.
        """
        for batch in iter(self.test_dataloader):
            self._on_epoch_end("test", batch, trainer, pl_module)

    def on_test_end(self, trainer, pl_module):
        if getattr(pl_module.hparams, "benchmark_logging", False) and hasattr(pl_module, "logging") and not pl_module.logging["log"].empty:
            save_path = pl_module.log_path
            os.makedirs(save_path, exist_ok=True)

            current_time_str = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"benchmark_log_{current_time_str}.csv"
            filepath = os.path.join(save_path, filename)

            pl_module.logging["log"].to_csv(filepath, index_label="id")
            print(f"Benchmark log successfully saved to: {filepath}")
